{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning & Wrangling\n",
    "\n",
    "#### 2.1. Initial review - data shape, type & content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We noticed the data doesn't have column names, so we'll read it without adding\n",
    "# headers and add the column names afterwards\n",
    "\n",
    "data = pd.read_csv('data/creditcardmarketing.csv', header=None)\n",
    "\n",
    "columns = ['customer_number', 'offer_accepted', 'reward', 'mailer_type', \\\n",
    "    'income_level', 'bank_accounts_open', 'overdraft_protection', \\\n",
    "    'credit_rating', 'credit_cards_held', 'homes_owned', 'household_size', \\\n",
    "    'home_owner', 'average_balance', 'balance_Q1', 'balance_Q2', 'balance_Q3', \\\n",
    "    'balance_Q4']\n",
    "\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check characteristics of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see that in the balance columns there are 24 null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice the `customer_column` which we can use as our index column after ensuring it doesn't have any duplicate values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data['customer_number'].unique())/data.shape[0]) # equal to 1, so no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('customer_number', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in the categorical columns:\n",
    "cat = data.select_dtypes(object)\n",
    "\n",
    "for col in cat.columns:\n",
    "    print(col, \":\", cat[col].unique()) # No odd entries, so no cleaning required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in the discrete numerical columns\n",
    "\n",
    "# Split the numerical data into discrete & continuous data\n",
    "def split_numericals(data, threshold=10):\n",
    "    num = data.select_dtypes(np.number)\n",
    "    cont_columns = []\n",
    "    disc_columns = []\n",
    "    for col in num.columns:\n",
    "        if len(num[col].unique()) > threshold:\n",
    "            cont_columns.append(col)\n",
    "        else:\n",
    "            disc_columns.append(col)\n",
    "    num_cont = data.loc[:, cont_columns]\n",
    "    num_disc = data.loc[:, disc_columns]\n",
    "    return num_cont, num_disc\n",
    "\n",
    "num_cont, num_disc = split_numericals(data)\n",
    "\n",
    "# Check the unique values\n",
    "for col in num_disc.columns:\n",
    "    print(col, \":\", num_disc[col].unique()) # No odd entries, so no cleaning required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Data Cleaning\n",
    "\n",
    "As the data set is already relatively clean and the data types are correct, we only need to handle the null values in the balance columns. We will start by checking the maximum percentage of nulls within a row, to decide whether or not it would be more beneficial to remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_nulls_rows(df):\n",
    "    nulls_percentage = []\n",
    "    for index in df.index:\n",
    "        number_of_nulls = df.loc[index,].isna().sum()\n",
    "        null_percentage = round(number_of_nulls * 100 / df.shape[1], 1)\n",
    "        nulls_percentage.append(null_percentage)\n",
    "    return max(nulls_percentage)\n",
    "\n",
    "max_nulls_rows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given some rows have 31% null values, it might be better to drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape # We can see we dropped the customers with NaN values across \\\n",
    "           # all balance columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis\n",
    "\n",
    "#### 3.1. Categorical & discrete numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of plots\n",
    "print(\"cat column number:\", cat.shape[1])\n",
    "print(\"num_disc column number:\", num_disc.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_plotter(cat_or_num_disc, plot_type=sns.countplot):\n",
    "    col_number = len(cat_or_num_disc.columns)\n",
    "    for i in range(0, col_number, 2):\n",
    "        column_1 = cat_or_num_disc.columns[i]\n",
    "        try:\n",
    "            column_2 = cat_or_num_disc.columns[i + 1]\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(12, 4))        \n",
    "            plot_type(x=column_2, data=cat_or_num_disc, ax=ax[1], color='b')\n",
    "            plot_type(x=column_1, data=cat_or_num_disc, ax=ax[0], color='c')        \n",
    "        except:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(6, 4))  \n",
    "            plot_type(x=column_1, data=cat_or_num_disc, color='c')              \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_plotter(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the `offer_accepted`, `overdraft_protection`, and `home_owner` are imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_plotter(num_disc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice we have a very small representation of customers that:\n",
    "- have 3 open bank accounts\n",
    "* have 4 credit card accounts\n",
    "- own 3 houses\n",
    "* belong to a household of more than 6 people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Numerical continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_plotter(num_cont, plot_type=sns.histplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the average, Q2 & Q3 balances have relatively normal distributions, whereas the Q1 & Q4 balances generally tend to be on the lower side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_plotter(num_cont, plot_type=sns.boxplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how the `average_balance` is distributed depending on various categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat.columns:\n",
    "    sns.boxplot(x='average_balance', y=col, data=data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_disc.columns:\n",
    "    sns.boxplot(x=col, y='average_balance', data=data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the `average_balance` has a similar distribution across all categorical & discrete numerical attributes, except for `household_size` (n=8, 9), where there were only two data points present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at how categorical & discrete numerical features correlate to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_v_home_owner = pd.crosstab(data['offer_accepted'], data['home_owner'])\n",
    "print(offer_v_home_owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_v_credit_rating = pd.crosstab(data['offer_accepted'], data['credit_rating'])\n",
    "print(offer_v_credit_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "data.corr()\n",
    "\n",
    "# Create heatmap\n",
    "mask = np.zeros_like(data.corr())\n",
    "mask[np.triu_indices_from(mask)] = True \n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.heatmap(data.corr(), mask=mask, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the `average_balance` is highly correlated with all the other balances (which is to be expected), whereas the quarterly balance is highly correlated with the previous quarter's balance, which is again to be expected. In further modelling, we might want to use the `average_balance` rather than all the quarterly balances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean dataframe to a new .csv file to be used in further analysis\n",
    "data.to_csv('creditcardmarketing_post_cleaning.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
